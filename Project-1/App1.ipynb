{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5656da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5f32de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000002D5A90B0670> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002D5A90B3970> root_client=<openai.OpenAI object at 0x000002D5A90B0C10> root_async_client=<openai.AsyncOpenAI object at 0x000002D5A90B2290> model_name='gpt-5-nano-2025-08-07' model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano-2025-08-07\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48a559e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke('Apa itu gen ai?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5de8f28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Gen AI adalah singkatan dari Generative AI atau AI generatif. Ini adalah jenis kecerdasan buatan yang bisa menciptakan konten baru, bukan sekadar menilai atau mengklasifikasikan data.\\n\\nGampangkan definisi:\\n- AI generatif membuat teks, gambar, suara, kode, musik, video, dan bentuk konten lainnya berdasarkan pola yang dipelajari dari data besar.\\n- Modelnya biasanya berbasis arsitektur seperti transformer (untuk teks) atau diffusion (untuk gambar).\\n\\nContoh umum:\\n- Teks: ChatGPT, GPT-4\\n- Gambar: DALL-E, Stable Diffusion\\n- Suara/ucapan: model pengubah suara, Whisper (speech-to-text)\\n- Kode: Codex\\n- Musik: beberapa model generatif untuk komposisi musik\\n\\nKegunaan utama:\\n- Membuat konten baru dengan cepat (artikel, ringkasan, desain, kode, ilustrasi).\\n- Prototyping ide, brainstorming, dan assistive writing.\\n- Personalisasi konten dan pembuatan materi kreatif.\\n\\nKelemahan dan pertimbangan:\\n- Bisa menghasilkan informasi yang salah (hallucinations) atau bias.\\n- Berisiko terkait hak cipta, privasi, dan penyalahgunaan konten.\\n- Kebutuhan sumber daya komputasi dan biaya penggunaan API/ layanan.\\n\\nCara mulai singkat:\\n- Coba aplikasi langsung seperti ChatGPT untuk teks, DALL-E atau Stable Diffusion untuk gambar.\\n- Jika Anda pengembang, gunakan API seperti OpenAI API, Google Vertex AI, atau platform lain untuk membangun solusi Gen AI.\\n\\nMau saya jelaskan lebih lanjut dengan contoh penggunaan spesifik Anda (misalnya menulis konten, membuat gambar, atau kode otomatis)?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1397, 'prompt_tokens': 11, 'total_tokens': 1408, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1024, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CSFOWrsm1Dfn9SXgbpvCl2sfjgpCx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--d811967a-8358-4fd4-9640-a84175fd6966-0' usage_metadata={'input_tokens': 11, 'output_tokens': 1397, 'total_tokens': 1408, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1024}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08801b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### pROMPT TEMPLATE\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a377898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='kamu adalah seorang ahli dalam ai engineer, berikan saya jawaban yang berhubungan'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"kamu adalah seorang ahli dalam ai engineer, berikan saya jawaban yang berhubungan\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8f68f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"input\" : \"Bisakah kamu beri tahu langsmith untuk apa?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc35009b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Singkatnya, LangSmith adalah alat observabilitas untuk aplikasi LLM yang dibangun dengan LangChain. Tujuannya adalah memudahkan Anda merekam, memantau, menguji, dan membedah interaksi dengan model sehingga debugging, perbandingan performa, dan reproducibility menjadi lebih mudah.\\n\\nApa yang LangSmith bisa dipakai untuk:\\n- Observability dan replay: merekam input prompt, output model, metadata (model, suhu, versi API, etc.) serta latensi, lalu memutarnya kembali (replay) untuk dianalisis.\\n- Debugging dan reproduksi masalah: melihat mengapa sebuah jawaban berbeda, mengidentifikasi bottleneck, atau bug dalam rantai (chain) LangChain.\\n- Pengujian dan evaluasi: membangun test suite untuk mengevaluasi jawaban model secara otomatis, membandingkan beberapa prompts/konfigurasi/model, serta mendeteksi regresi.\\n- Audit dan kepatuhan: menyimpan jejak prompt, sistem prompt, model yang dipakai, dan parameter lain untuk audit atau governance.\\n- Kolaborasi tim: berbagi run, membuat catatan/annotasi, dan membangun dashboard analitik bersama rekan tim.\\n- Analitik performa: melacak latency, biaya per token, tingkat kesalahan, dan variasi kinerja antar model atau prompt.\\n\\nCara mulai (tingkat tinggi):\\n- Pasang paket LangSmith dan konfigurasikan API key project dari dashboard LangSmith.\\n- Instrumentasikan kode Anda untuk mencatat run dengan input, output, dan metadata menggunakan API LangSmith.\\n- Gunakan UI LangSmith untuk menjelajah run, membandingkan hasil, memutar ulang, dan menambahkan anotasi.\\n\\nContoh pola kerja (konsep):\\n- Mulai sebuah run\\n- Log input (prompt) dan konteks\\n- Panggil model/LLM\\n- Log output (jawaban) serta metadata (model, suhu, dll.)\\n- Selesaikan run\\n- Lihat di dashboard untuk analisis, perbandingan, atau replay\\n\\nPseudo-code (konsep, sesuaikan dengan API yang Anda pakai):\\n- client = LangSmithClient(api_key=\"YOUR_API_KEY\")\\n- with client.start_run(name=\"my-long-running-chain\") as run:\\n-     run.log_input({\"prompt\": prompt, \"context\": context})\\n-     output = llm.generate(prompt)\\n-     run.log_output({\"response\": output})\\n-     run.log_metadata({\"model\": \"gpt-4\", \"temperature\": 0.2})\\n- run.complete()\\n\\nCatatan:\\n- Nama fungsi dan cara integrasinya dapat berbeda tergantung versi library LangSmith yang Anda pakai. Silakan cek dokumentasi resmi LangSmith untuk contoh kode aktual, instalasi, dan cara konfigurasi API key.\\n- Pastikan Anda menghapus atau men-redact data sensitif sebelum logging jika ada data rahasia di prompt atau respons.\\n\\nJika Anda mau, saya bisa kasih contoh kode konkret sesuai bahasa/pustaka yang Anda pakai (Python dengan LangSmith Python SDK, atau integrasi LangChain), berikut langkah-langkah dan snippet yang bisa langsung dijalankan.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2059, 'prompt_tokens': 38, 'total_tokens': 2097, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1408, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CSFb61hWhkeql8RAsCGNKUAt3xPU7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--5821e794-d5dd-4f97-abf2-648d123549f7-0', usage_metadata={'input_tokens': 38, 'output_tokens': 2059, 'total_tokens': 2097, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1408}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8df9f422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "969436e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stroutput parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt|llm|output_parser\n",
    "\n",
    "response = chain.invoke({\"input\" : \"Bisakah kamu beri tahu langsmith untuk apa?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32573932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Singkatnya: LangSmith adalah platform dari LangChain untuk logging, debugging, pengujian, dan observabilitas aplikasi LLM yang dibangun dengan LangChain.\\n\\nGuna apa LangSmith (tujuan utama):\\n- Debugging dan reproduce bug: lihat alur eksekusi, input/output, error, dan bagaimana chain berinteraksi.\\n- Observabilitas performa: pantau latensi, penggunaan token, biaya, dan fluktuasi performa antar versi model.\\n- Evaluasi dan perbandingan model: bandingkan dua versi model atau dua konfigurasi prompt/template dengan mudah.\\n- Dokumentasi dan audit: simpan jejak Eksperimen/Runs, termasuk prompt, respons, dan metadata, untuk audit atau kepatuhan.\\n- Kolaborasi tim: bagikan temuan, templat evaluasi, dan run yang relevan dengan developer lain atau stakeholder.\\n\\nFitur utama:\\n- Perekaman run LangChain secara terpusat: input, output, prompt, chain calls, error, metadata.\\n- Logging artifacts dan data terkait (mis. contoh respons, embeddings, prompt templates).\\n- Observabilitas performa: metrik seperti latensi, token usage, error rate.\\n- Analisis dan evaluasi: filter, bandingkan run, buat evaluasi kustom.\\n- Dashboards dan UI untuk menelusuri runs, memudahkan debugging.\\n- Reproduksi dan versioning eksperimen.\\n\\nCara mulai secara ringkas:\\n- Install dan setup: daftarkan API key/workspace di LangSmith, install klien LangSmith.\\n- Instrumentasi kode: tambahkan logging LangSmith saat menjalankan chain (mis. saat menjalankan prompt dan menerima respons).\\n- Pelajari hasilnya: buka UI LangSmith untuk melihat run, periksa input/output, error, dan metrik; bandingkan versi model atau prompt.\\n- Gunakan untuk QA dan evaluasi berkelanjutan: buat eksperimen, tambahkan evaluasi, dan bagikan temuan.\\n\\nContoh penggunaan umum:\\n- Men-debug mengapa sebuah prompt menghasilkan hasil yang buruk pada model tertentu.\\n- Membandingkan dua versi model dengan prompt yang sama untuk melihat perubahan performa.\\n- Memonitor biaya token dan latensi dalam aplikasi produksi.\\n- Menyimpan contoh prompt-respon untuk dokumentasi internal dan kepatuhan.\\n\\nJika kamu mau, saya bisa kasih panduan langkah-demi-langkah dengan contoh kode singkat (ya/tidak) untuk mulai menggunakan LangSmith sesuai tumpukan tech yang kamu pakai.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a2144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
